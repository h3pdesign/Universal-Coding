{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Access your data in Azure Notebooks\n",
        "\n",
        "Data is the lifeblood of notebooks. Jupyter itself provides only a runtime environment for a notebook, and thus to do intresting work you need to bring data in from elsewhere.\n",
        "\n",
        "This notebook provides examples of different ways to import data, all in a format that you can run and experience directly.\n",
        "\n",
        "- [Use curl to retrieve a file from GitHub](#curl)\n",
        "- [Use a REST API to retrieve online data](#restapi)\n",
        "- [Query an Azure SQL database](#azuresql)\n",
        "- [Access Azure Table Storage](#tablestorage)\n",
        "- [Access Azure Blobs](#blobs)\n",
        "  - [Share access to Azure Storage through Shared Access Signatures](#sharedaccess)\n",
        "- [Other Azure databases (references)](#otherdbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use `curl` to retrieve a file from the Internet <a name=\"curl\"></a> \n",
        "\n",
        "In Python notebooks, you can invoke the command line using `!`, which allows you to download files directly from the Internet using a tool like `curl`, `wget`, and so on. For example, the following `curl` command downloads a file containing oil price data from GitHub, and stores it in the project as the file *oil_price_temp.csv*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!curl https://raw.githubusercontent.com/petroleum101/figures/db46e7f48b8aab67a0dfe31696f6071fb7a84f1e/oil_price/oil_price.csv -o ../oil_price_temp.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the file is in the project, you can load it using any suitable code. For example, you can load it into a pandas dataframe, after which you can work with it however you like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "dataframe_file = pandas.read_csv('../oil_price_temp.csv')\n",
        "dataframe_file.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use REST APIs to retrieve online data <a name=\"restapi\"></a>\n",
        "\n",
        "Generally speaking, the vast amount of data available from the Internet is accessed not through files, but through REST APIs. Fortunately, because a notebook cell can contain whatever code you like, you can use code to send requests and receive JSON data. You can then convert that JSON into whatever format you want to use, such as a pandas dataframe.\n",
        "\n",
        "The following example is taken from https://dev.socrata.com/foundry/data.cityofnewyork.us/gkne-dk5s, which provides a dataset for 2014 New York Taxis. The sodapy library is used in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install sodapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code cell produces a warning about requests being throttled because you're not using an API key. This warning can be safely ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# From https://dev.socrata.com/foundry/data.cityofnewyork.us/gkne-dk5s\n",
        "# (select the \"Python pandas\") tab under \"Code Snippets\".\n",
        "\n",
        "import pandas\n",
        "from sodapy import Socrata\n",
        "\n",
        "# Unauthenticated client only works with public data sets. Note 'None'\n",
        "# in place of application token, and no username or password:\n",
        "client = Socrata(\"data.cityofnewyork.us\", None)\n",
        "\n",
        "# Example authenticated client (needed for non-public datasets):\n",
        "# client = Socrata(data.cityofnewyork.us,\n",
        "#                  MyAppToken,\n",
        "#                  userame=\"user@example.com\",\n",
        "#                  password=\"AFakePassword\")\n",
        "\n",
        "# First 20 results, returned as JSON from API / converted to Python list of\n",
        "# dictionaries by sodapy.\n",
        "results = client.get(\"gkne-dk5s\", limit=20)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "dataframe_rest1 = pandas.DataFrame.from_records(results)\n",
        "print(dataframe_rest1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A general data request can just use the requests module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import requests\n",
        "\n",
        "data_url = 'https://data.cityofnewyork.us/resource/gkne-dk5s.json'\n",
        "\n",
        "# General data request; include other API keys and credentials as needed in the data argument\n",
        "response = requests.get(data_url, data={\"limit\" : \"20\"})\n",
        "\n",
        "if response.status_code == 200:\n",
        "    dataframe_rest2 = pandas.DataFrame.from_records(response.json())    \n",
        "    print(dataframe_rest2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query an Azure SQL database  <a name=\"azuresql\"></a>\n",
        "\n",
        "You can access SQL Server databases with the assistance of the pyodbc library.\n",
        "\n",
        "For this article, follow the instruction in [Use Python to query an Azure SQL database](https://docs.microsoft.com/azure/sql-database/sql-database-connect-query-python) to create a database containing AdventureWorks data. The code below, taken from that article, queries the database using pyodbc.\n",
        "\n",
        "**IMPORTANT**: To run the code, you must change the placeholders to provide identify your specific SQL Server instance and to provide your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install pyodbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pyodbc\n",
        "\n",
        "# Uncomment and modify these four variables for your particular instance\n",
        "# Follow https://docs.microsoft.com/azure/sql-database/sql-database-connect-query-python to create a suitable database.\n",
        "# server = 'your_server.database.windows.net'\n",
        "# database = 'your_database'\n",
        "# username = 'your_username'\n",
        "# password = 'your_password'\n",
        "\n",
        "\n",
        "driver= '{ODBC Driver 13 for SQL Server}'\n",
        "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
        "cursor = cnxn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT TOP 20 pc.Name as CategoryName, p.name as ProductName FROM [SalesLT].[ProductCategory] pc JOIN [SalesLT].[Product] p ON pc.productcategoryid = p.productcategoryid\")\n",
        "row = cursor.fetchone()\n",
        "\n",
        "while row:\n",
        "    print (str(row[0]) + \" \" + str(row[1]))\n",
        "    row = cursor.fetchone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Azure Storage<a name=\"tablestorage\"></a>\n",
        "\n",
        "Azure Storage provides several different types of non-relational storage, depending on the type of data you have and how you need to access it:\n",
        "\n",
        "- Table Storage: provides low-cost, high-volume storage for tabular data, such as collected sensor logs, diagnostic logs, and so on.\n",
        "- Blob storage: provides file-like storage for any type of data.\n",
        "\n",
        "Azure CosmosDB is also a form of non-relational storage for JSON documents; see the [Other Azure databases](#otherdbs) section for more information on CosmosDB and a variety of other options.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "**IMPORTANT**: To run this code, you must create your own Azure Storage account and specify your account name and key in the variables below. For more information, see the following articles:\n",
        "\n",
        "- [Create a storage account](https://docs.microsoft.com/azure/storage/common/storage-quickstart-create-account?tabs=portal)\n",
        "- [Copy your credentials from the Azure portal](https://docs.microsoft.com/azure/storage/blobs/storage-quickstart-blobs-python#copy-your-credentials-from-the-azure-portal). Put simply, on the Azure portal, go to the storage account and navigate to **Settings** > **Access keys**. Then copy either **key1** or **key2** and paste into the applicable code cells in this section.\n",
        "- Install the azure-storage library (used for tables and blobs), which is done with the following code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install azure-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table storage\n",
        "\n",
        "The following code creates a table in a specified Azure Storage account, then adds rows, removes rows, and queries data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Modify these variables with your specific values obtained in the Prerequisites section\n",
        "azure_storage_account_name = \"your_storage_account\"\n",
        "azure_storage_account_key = \"your_access_key\"\n",
        "\n",
        "if azure_storage_account_name is None or azure_storage_account_key is None:\n",
        "    raise Exception(\"Provide your specific name and key for your Azure Storage account--see the Prerequisites section earlier.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from azure.storage.table import TableService\n",
        "import IPython\n",
        "\n",
        "# Connect to the table - change the placeholders to your specific names\n",
        "table_service = TableService(azure_storage_account_name, azure_storage_account_key)\n",
        "\n",
        "# Create a table\n",
        "table_name = 'azurenotebookstesttable'\n",
        "table_service.create_table(table_name)\n",
        "\n",
        "# Insert entities into the table\n",
        "entity = {'PartitionKey': 'testItems', 'RowKey': '0', 'age':1}\n",
        "table_service.insert_entity(table_name, entity)\n",
        "table_service.insert_entity(table_name, {'PartitionKey': 'testItems', 'RowKey': '10', 'age':2, 'eyecolor':'blue'})\n",
        "\n",
        "# Query the table\n",
        "queried_entities = table_service.query_entities(table_name, filter=\"PartitionKey eq 'testItems'\")\n",
        "print('=== Queried rows after inserts ===')\n",
        "IPython.display.display_pretty([i for i in queried_entities])\n",
        "\n",
        "# Delete an entity by using its partition and row key.\n",
        "table_service.delete_entity(table_name, 'testItems', '0')\n",
        "                                         \n",
        "# Query again to show that the entity was removed\n",
        "queried_entities = table_service.query_entities(table_name, filter=\"PartitionKey eq 'testItems'\")\n",
        "print('=== Queried rows after delete ===')\n",
        "IPython.display.display_pretty([i for i in queried_entities])\n",
        "\n",
        "# Clean up resources\n",
        "table_service.delete_table('azurenotebookstesttable')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Access Azure Blobs <a name=\"blobs\"></a>\n",
        "\n",
        "Blobs store file-like data, which can be private or public. \n",
        "\n",
        "The code below demonstrates private keys first. It creates a container, then creates a blob, then reads that blob.\n",
        "\n",
        "The [shared access](#sharedaccess) section then demonstrates a shared access signature for public read-only access.\n",
        "\n",
        "You can also put content into blobs using [AzCopy](https://azure.microsoft.com/en-us/documentation/articles/storage-use-azcopy/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Modify these variables with your specific values obtained in the Prerequisites section\n",
        "azure_storage_account_name = \"your_storage_account\"\n",
        "azure_storage_account_key = \"your_access_key\"\n",
        "\n",
        "if azure_storage_account_name is None or azure_storage_account_key is None:\n",
        "    raise Exception(\"Provide your specific name and key for your Azure Storage account--see the Prerequisites section earlier.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from azure.storage.blob import BlockBlobService\n",
        "\n",
        "# Connect to our blob via the BlobService\n",
        "blob_service = BlockBlobService(azure_storage_account_name, azure_storage_account_key)\n",
        "\n",
        "# Create a container\n",
        "blob_service.create_container('azure-notebooks-data')\n",
        "\n",
        "# Insider a container, create other containers or blobs\n",
        "blob_service.create_blob_from_text('azure-notebooks-data', 'sample.txt', 'Hello, Blobs! This is content for the sample.txt file.')\n",
        "\n",
        "# You can list containers and blobs\n",
        "containers = blob_service.list_containers()\n",
        "blobs = blob_service.list_blobs('azure-notebooks-data')\n",
        "\n",
        "# Read a blob from and get the text; the copy is stored in the Azure Notebooks project\n",
        "blob_service.get_blob_to_path('azure-notebooks-data', 'sample.txt', 'sample.txt')\n",
        "\n",
        "# Clean up the created blob and container\n",
        "blob_service.delete_blob('azure-notebooks-data', 'sample.txt')\n",
        "blob_service.delete_container('azure-notebooks-data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the contents of the sample blob file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!cat sample.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Provide public read-only access to Azure Storage through shared access signatures <a name=\"sharedaccess\"></a>\n",
        "\n",
        "Sometimes you want to share data from Azure Storage without providing editing capabilities. Shared Access Signatures allow you to share your data and provide whatever level of control you want to the receiver.\n",
        "\n",
        "The code below creates a shared access signature with read permissions for a table (it also works with blobs). The code then demonstrates the ability to read but not write. Additional permissions are also necessary to query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Modify these variables with your specific values obtained in the Prerequisites section\n",
        "azure_storage_account_name = \"your_storage_account\"\n",
        "azure_storage_account_key = \"your_access_key\"\n",
        "\n",
        "if azure_storage_account_name is None or azure_storage_account_key is None:\n",
        "    raise Exception(\"Provide your specific name and key for your Azure Storage account--see the Prerequisites section earlier.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a container and a blob in that container\n",
        "from azure.storage.blob import BlockBlobService\n",
        "\n",
        "# Connect to our blob via the BlobService\n",
        "blob_service = BlockBlobService(azure_storage_account_name, azure_storage_account_key)\n",
        "\n",
        "# Create a container\n",
        "blob_service.create_container('azure-notebooks-data')\n",
        "\n",
        "# Insider a container, create other containers or blobs\n",
        "blob_service.create_blob_from_text('azure-notebooks-data', 'sample.txt', 'Hello, Blobs! This is content for the sample.txt file.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a shared access signature\n",
        "from azure.storage.blob.models import BlobPermissions\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "sas_token = blob_service.generate_blob_shared_access_signature(\n",
        "    'azure-notebooks-data',\n",
        "    'sample.txt',\n",
        "    BlobPermissions.READ,\n",
        "    datetime.utcnow() + timedelta(hours=1)\n",
        ")\n",
        "\n",
        "print(sas_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a service and use the shared access signature\n",
        "sas_blob_service = BlockBlobService(account_name=azure_storage_account_name, sas_token=sas_token, )\n",
        "\n",
        "sas_blob_service.get_blob_to_text('azure-notebooks-data', 'sample.txt').content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Clean up the created blob and container\n",
        "blob_service.delete_blob('azure-notebooks-data', 'sample.txt')\n",
        "blob_service.delete_container('azure-notebooks-data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query other Azure databases  <a name=\"otherdbs\"></a>\n",
        "\n",
        "Azure provides a number of other database types that you can use. The articles below provide guidance for accessing those databases from Python:\n",
        "\n",
        "- Azure Cosmos DB (fully-indexed NoSQL store for JSON documents):\n",
        "  - [Build a SQL API app with Python](https://docs.microsoft.com/azure/cosmos-db/create-sql-api-python)\n",
        "  - [Build a Flask app with the MongoDB API](https://docs.microsoft.com/azure/cosmos-db/create-mongodb-flask)\n",
        "  - [Create a graph database using Python and the Gremlin API](https://docs.microsoft.com/azure/cosmos-db/create-graph-python)\n",
        "  - [Build a Cassandra app with Python and Azure Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/create-cassandra-python)\n",
        "  - [Build a Table API app with Python and Azure Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/create-table-python)\n",
        "- [Azure Database for PostgreSQL: Use Python to connect and query data](https://docs.microsoft.com/azure/postgresql/connect-python)\n",
        "- [Quickstart: Use Azure Redis Cache with Python](https://docs.microsoft.com/azure/redis-cache/cache-python-get-started)\n",
        "- [Azure Database for MySQL: Use Python to connect and query data](https://docs.microsoft.com/azure/mysql/connect-python)\n",
        "- [Azure Data Factory](https://azure.microsoft.com/en-us/services/data-factory/)\n",
        "  - [Copy Wizard for Azure Data Factory](https://azure.microsoft.com/en-us/updates/code-free-copy-wizard-for-azure-data-factory/)\n",
        "\n",
        "Note that for CosmosDB, you can use the [azure-cosmosdb-table](https://pypi.org/project/azure-cosmosdb-table/) library (`!pip install azure-cosmosdb-table`)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
