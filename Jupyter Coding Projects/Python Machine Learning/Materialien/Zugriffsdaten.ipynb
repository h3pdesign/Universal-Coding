{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten Bereinigen: Zugriffe auf Webseite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Beispiel werden wir echte Zugriffe auf eine Webseite analysieren, und so herausfinden, welches die am häufigsten besuchten Unterseiten sind. Klingt einfach, oder?\n",
    "\n",
    "Zuerst definieren wir einen regulären Ausdruck, der uns bei dem Auslesen einer Zeile aus der Log-Datei unterstützt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "format_pat= re.compile(\n",
    "    r\"(?P<host>[\\d\\.]+)\\s\"\n",
    "    r\"(?P<identity>\\S*)\\s\"\n",
    "    r\"(?P<user>\\S*)\\s\"\n",
    "    r\"\\[(?P<time>.*?)\\]\\s\"\n",
    "    r'\"(?P<request>.*?)\"\\s'\n",
    "    r\"(?P<status>\\d+)\\s\"\n",
    "    r\"(?P<bytes>\\S*)\\s\"\n",
    "    r'\"(?P<referer>.*?)\"\\s'\n",
    "    r'\"(?P<user_agent>.*?)\"\\s*'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Pfad zur Datei, die wir analysieren wollen. Die Datei liegt im selben Ordner, also brauchen wir hier nichts anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logPath = \"access_log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes schreiben wir ein kleines Script, welches die Datei Zeile für Zeile durchgeht, und die Daten in ein Dictionary schreibt. In diesem Dictionary wird dann als Schlüssel die URL der Seite gepseichert, und als Wert die Anzahl der aufrufe. Was könnte hierbei schief gehen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2652988b1667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'request'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# request = \"GET /hallo-welt.html HTTP/1.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mURLCounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mURLCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURLCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            request = access['request']\n",
    "            # request = \"GET /blog/ HTTP/1.1\" \n",
    "            (action, URL, protocol) = request.split()\n",
    "            if URL in URLCounts:\n",
    "                URLCounts[URL] = URLCounts[URL] + 1\n",
    "            else:\n",
    "                URLCounts[URL] = 1\n",
    "\n",
    "results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result + \": \" + str(URLCounts[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mhm... Der \"request\" sollte eigentlich wie folgt aussehen:\n",
    "\n",
    "`GET /blog/ HTTP/1.1`\n",
    "\n",
    "Zuerst die HTTP-Methode (GET / POST), dann die URL, und dann das Protokoll. Aber das scheint nicht immer zu klappen. Warum nicht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_\\\\xb0ZP\\\\x07tR\\\\xe5']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            request = access['request']\n",
    "            fields = request.split()\n",
    "            if (len(fields) != 3):\n",
    "                print(fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mhm... Also es gibt einige Einträge, in denen der request einfach nur leer ist, bei einem anderen steht dort einfach nur Müll drinnen. Also passen wir unser Script an, dass diese Fälle abgefangen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/xmlrpc.php: 68494\n",
      "/wp-login.php: 1923\n",
      "/: 440\n",
      "/blog/: 138\n",
      "/robots.txt: 123\n",
      "/sitemap_index.xml: 118\n",
      "/post-sitemap.xml: 118\n",
      "/page-sitemap.xml: 117\n",
      "/category-sitemap.xml: 117\n",
      "/orlando-headlines/: 95\n",
      "/san-jose-headlines/: 85\n",
      "http://51.254.206.142/httptest.php: 81\n",
      "/comics-2/: 76\n",
      "/travel/: 74\n",
      "/entertainment/: 72\n",
      "/world/: 70\n",
      "/business/: 70\n",
      "/national-headlines/: 70\n",
      "/national/: 70\n",
      "/weather/: 70\n"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            request = access['request']\n",
    "            fields = request.split()\n",
    "            if (len(fields) == 3):\n",
    "                URL = fields[1]\n",
    "                if URL in URLCounts:\n",
    "                    URLCounts[URL] = URLCounts[URL] + 1\n",
    "                else:\n",
    "                    URLCounts[URL] = 1\n",
    "\n",
    "results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result + \": \" + str(URLCounts[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es hat funktioniert! Aber die Ergebnisse machen keinen Sinn. Was wir ja eigentlich wollten, sind die Seiten die von echten Menschen angeschaut werden. Und was ist diese xmlrpc.php? Wenn man sich dazu die Log-Datei näher anschaut, findet man viele Einträge in folgender Form:\n",
    "\n",
    "`46.166.xxx.xxx - - [05/Dec/2015:05:19:35 +0000] \"POST /xmlrpc.php HTTP/1.0\" 200 370 \"-\" \"Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)\"`\n",
    "\n",
    "Was macht dieses Script? Auf jeden Fall wollen wir nur GET - Anfrage betrachten. Warum?\n",
    "\n",
    "- `GET`: Anzeigen von irgendwelchen Daten im Internet\n",
    "- `POST`: Verändern / Löschen von irgendwelchen Daten, absenden eines Formulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/: 434\n",
      "/blog/: 138\n",
      "/robots.txt: 123\n",
      "/sitemap_index.xml: 118\n",
      "/post-sitemap.xml: 118\n",
      "/page-sitemap.xml: 117\n",
      "/category-sitemap.xml: 117\n",
      "/orlando-headlines/: 95\n",
      "/san-jose-headlines/: 85\n",
      "http://51.254.206.142/httptest.php: 81\n",
      "/comics-2/: 76\n",
      "/travel/: 74\n",
      "/entertainment/: 72\n",
      "/world/: 70\n",
      "/business/: 70\n",
      "/national-headlines/: 70\n",
      "/national/: 70\n",
      "/weather/: 70\n",
      "/defense-sticking-head-sand/: 69\n",
      "/about/: 69\n"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            request = access['request']\n",
    "            fields = request.split()\n",
    "            if (len(fields) == 3):\n",
    "                (action, URL, protocol) = fields\n",
    "                if (action == 'GET'):\n",
    "                    if URL in URLCounts:\n",
    "                        URLCounts[URL] = URLCounts[URL] + 1\n",
    "                    else:\n",
    "                        URLCounts[URL] = 1\n",
    "\n",
    "results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result + \": \" + str(URLCounts[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit haben wir jetzt alle POST - Anfragen aus den Ergebnissen herausgefiltert. Es sieht schonmal besser aus. Aber bei dieser Seite handelt es sich um eine News-Seite - warum lesen so viele Leute den kleinen Blog? Eigentlich sollten sie eher die News-Artikel lesen... \n",
    "\n",
    "Wie sieht denn ein typischer Eintrag für /blog/ aus?\n",
    "\n",
    "54.165.xxx.xxx - - [05/Dec/2015:09:32:05 +0000] \"GET /blog/ HTTP/1.0\" 200 31670 \"-\" \"-\"\n",
    "\n",
    "Mhm... warum ist bei diesem Eintrag der User-Agent leer? Könnte auf einen bösartigen Scraper oder sonst irgendwas komisches hindeuten. \n",
    "\n",
    "Was für User-Agents besuchen eigentlich unserer Webseite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0): 68484\n",
      "-: 4035\n",
      "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0): 1724\n",
      "W3 Total Cache/0.9.4.1: 468\n",
      "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html): 278\n",
      "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html): 248\n",
      "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36: 158\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0: 144\n",
      "Mozilla/5.0 (iPad; CPU OS 8_4 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12H143 Safari/600.1.4: 120\n",
      "Mozilla/5.0 (Linux; Android 5.1.1; SM-G900T Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.76 Mobile Safari/537.36: 47\n",
      "Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm): 43\n",
      "Mozilla/5.0 (compatible; MJ12bot/v1.4.5; http://www.majestic12.co.uk/bot.php?+): 41\n",
      "Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14: 40\n",
      "Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots): 27\n",
      "Ruby: 15\n",
      "Mozilla/5.0 (Linux; Android 5.1.1; SM-G900T Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.76 Mobile Safari/537.36: 15\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36: 13\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2: 11\n",
      "Mozilla/5.0 (compatible; AhrefsBot/5.0; +http://ahrefs.com/robot/): 11\n",
      "MobileSafari/600.1.4 CFNetwork/711.4.6 Darwin/14.0.0: 10\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.73 Safari/537.36: 9\n",
      "Mozilla/5.0 (compatible; YandexImages/3.0; +http://yandex.com/bots): 9\n",
      "Mozilla/5.0 (compatible; linkdexbot/2.0; +http://www.linkdex.com/bots/): 7\n",
      "Mozilla/5.0 (compatible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp): 6\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12F70 Safari/600.1.4 (compatible; Googlebot/2.1; +http://www.google.com/bot.html): 6\n",
      "Mozilla/5.0 (compatible; SeznamBot/3.2; +http://fulltext.sblog.cz/): 4\n",
      "Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36: 4\n",
      "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.28) Gecko/20120306 Firefox/3.6.28 (.NET CLR 3.5.30729): 4\n",
      "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1): 4\n",
      "Mozilla/5.0 zgrab/0.x: 4\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0: 3\n",
      "Opera/9.80 (Windows NT 5.1; U; ru) Presto/2.9.168 Version/11.50: 3\n",
      "Mozilla/5.0 (Windows NT 6.1; rv:34.0) Gecko/20100101 Firefox/34.0: 3\n",
      "Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1; 2Pac; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022): 3\n",
      "Mozilla/5.0: 3\n",
      "Mozilla/4.0 (compatible: FDSE robot): 3\n",
      "Mozilla/5.0 (compatible; spbot/4.4.2; +http://OpenLinkProfiler.org/bot ): 3\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0: 2\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36: 2\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:36.0) Gecko/20100101 Firefox/36.0: 2\n",
      "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36: 2\n",
      "Mozilla/5.0 (Windows NT 6.1; rv:28.0) Gecko/20100101 Firefox/28.0: 2\n",
      "netEstate NE Crawler (+http://www.website-datenbank.de/): 2\n",
      "Mozilla/5.0 (Windows NT 6.0; rv:29.0) Gecko/20120101 Firefox/29.0: 2\n",
      "Mozilla/5.0 (X11; U; FreeBSD x86_64; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16: 2\n",
      "Mozilla/5.0 (Windows NT 6.2; rv:24.0) Gecko/20100101 Firefox/24.0: 2\n",
      "Mozilla/4.0 (compatible; Netcraft Web Server Survey): 2\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:2.0.1) Gecko/20100101 Firefox/5.0: 2\n",
      "Opera/9.80 (Windows NT 6.1); U) Presto/2.10.289 Version/12.02: 2\n",
      "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.5) Gecko/20041107 Firefox/1.0: 2\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:28.0) Gecko/20100101 Firefox/28.0: 2\n",
      "Mozilla/5.0 (Windows NT 6.2; rv:31.0) Gecko/20100101 Firefox/31.0: 2\n",
      "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E): 2\n",
      "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36: 2\n",
      "Googlebot-Image/1.0: 2\n",
      "Mozilla/5.0 (Windows NT 6.2; WOW64; rv:36.0) Gecko/20100101 Firefox/36.0: 2\n",
      "Mozilla/5.0 (Windows NT 6.0; rv:31.0) Gecko/20100101 Firefox/31.0: 2\n",
      "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 5.1; Trident/5.0; .NET CLR 2.0.50727; .NET CLR 3.5.30729): 2\n",
      "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36: 1\n",
      "Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:42.0) Gecko/20100101 Firefox/42.0: 1\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0: 1\n",
      "Mozilla/3.0 (compatible; Indy Library): 1\n",
      "Mozilla/5.0 (Windows; U; Windows NT 5.0; fr-FR; rv:0.9.4) Gecko/20011019 Netscape6/6.2: 1\n",
      "facebookexternalhit/1.1 (+http://www.facebook.com/externalhit_uatext.php): 1\n",
      "NokiaE5-00/SymbianOS/9.1 Series60/3.0 3gpp-gba: 1\n",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36: 1\n",
      "Mozilla/5.0 (Windows NT 5.1; rv:32.0) Gecko/20100101 Firefox/31.0: 1\n",
      "Mozilla/5.0 (X11; U; Linux i686; pl-PL; rv:1.9.0.2) Gecko/20121223 Ubuntu/9.25 (jaunty) Firefox/3.8: 1\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.59.10 (KHTML, like Gecko) Version/5.1.9 Safari/534.59.10: 1\n",
      "Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20100101 Firefox/31.0: 1\n",
      "Scrapy/1.0.3 (+http://scrapy.org): 1\n",
      "Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko: 1\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2251.0 Safari/537.36: 1\n",
      "Mozilla/5.0 (Windows NT 10.0; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0: 1\n",
      "Mozilla/5.0 (Windows NT 6.1; rv:33.0) Gecko/20100101 Firefox/33.0: 1\n",
      "Telesphoreo: 1\n",
      "Mozilla/5.0 (Windows NT 6.1; rv:22.0) Gecko/20130405 Firefox/22.0: 1\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36 Scanning for research (researchscan.comsys.rwth-aachen.de): 1\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36: 1\n",
      "Opera/9.80 (Windows NT 6.2; WOW64); U) Presto/2.12.388 Version/12.14: 1\n",
      "Mozilla/4.0 (compatible; MSIE 6.0; MSIE 5.5; Windows 95) Opera 7.03 [de]: 1\n",
      "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.3.1.1) Gecko/20101203 Firefox/3.6.12 (.NET CLR 3.5.30309): 1\n",
      "Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; MAGWJS; rv:11.0) like Gecko: 1\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.73 Safari/537.36: 1\n",
      "Mozilla/5.0 (Windows; U; Windows NT 5.1; fr; rv:1.9.0.13) Gecko/2009073022 Firefox/3.0.13 (.NET CLR 3.5.30729): 1\n"
     ]
    }
   ],
   "source": [
    "UserAgents = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            agent = access['user_agent']\n",
    "            if agent in UserAgents:\n",
    "                UserAgents[agent] = UserAgents[agent] + 1\n",
    "            else:\n",
    "                UserAgents[agent] = 1\n",
    "\n",
    "results = sorted(UserAgents, key=lambda i: int(UserAgents[i]), reverse=True)\n",
    "\n",
    "for result in results:\n",
    "    print(result + \": \" + str(UserAgents[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puuhh... Zusätzlich zum User Agent \"-\" gibt es unglaublich viele verschiedene, automatisierte Scripts die unsere Webseite aufrufen und so unsere Statistik verschmutzen. \n",
    "\n",
    "Jetzt könnten wir diese User-Agents manuell herausfiltern, aber das Einfachste ist jetzt erstmal, einfach alle Einträge zu verwerfen, bei denen der User-Agent \"-\", \"bot\", \"spider\" oder \"W3 Total Cache\" enthält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/: 77\n",
      "/orlando-headlines/: 36\n",
      "/?page_id=34248: 28\n",
      "/wp-content/cache/minify/000000/M9AvyUjVzUstLy7PLErVz8lMKkosqtTPKtYvTi7KLCgpBgA.js: 27\n",
      "/wp-content/cache/minify/000000/lY7dDoIwDIVfiG0KxkfxfnbdKO4HuxICTy-it8Zw15PzfSftzPCckJem-x4qUWArqBPl5mygZLEgyhdOaoxToGyGaiALiOfUnIz0qDLOdSZGE-nOlpc3kopDzrSyavVVt_veb5qSDVhjsQ6dHh_B_eE_z2pYIGJ7iBWKeEio_eT9UQe4xHhDll27mGRryVu_pRc.js: 27\n",
      "/wp-content/cache/minify/000000/M9bPKixNLarUy00szs8D0Zl5AA.js: 27\n",
      "/wp-content/cache/minify/000000/fY45DoAwDAQ_FMvkRQgFA5ZyWLajiN9zNHR0O83MRkyt-pIctqYFJPedKyYzfHg2PzOFiENAzaD07AxcpKmTolORvDjZt8KEfhBUGjZYCf8Fb0fvA1TXCw.css: 25\n",
      "/?author=1: 21\n",
      "/wp-content/cache/minify/000000/hcrRCYAwDAXAhXyEjiQ1YKAh4SVSx3cE7_uG7ASr4M9qg3kGWyk1adklK84LHtRj_My6Y0Pfqcz-AA.js: 20\n",
      "/wp-content/uploads/2014/11/nhn1.png: 19\n",
      "/wp-content/cache/minify/000000/BcGBCQAgCATAiUSaKYSERPk3avzuht4SkBJnt4tHJdqgnPBqKldesTcN1R8.js: 17\n",
      "/wp-includes/js/wp-emoji-release.min.js?ver=4.3.1: 17\n",
      "/wp-login.php: 16\n",
      "/comics-2/: 12\n",
      "/world/: 12\n",
      "/favicon.ico: 10\n",
      "/wp-content/uploads/2014/11/jumble.jpg: 6\n",
      "/wp-content/uploads/2014/11/violentcrime.jpg: 6\n",
      "/wp-content/uploads/2014/11/garfield.jpg: 6\n",
      "/wp-content/uploads/2014/11/babyblues.jpg: 6\n"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            agent = access['user_agent']\n",
    "            if (not('bot' in agent or 'spider' in agent or \n",
    "                    'Bot' in agent or 'Spider' in agent or\n",
    "                    'W3 Total Cache' in agent or agent =='-')):\n",
    "                request = access['request']\n",
    "                fields = request.split()\n",
    "                if (len(fields) == 3):\n",
    "                    (action, URL, protocol) = fields\n",
    "                    if (action == 'GET'):\n",
    "                        if URL in URLCounts:\n",
    "                            URLCounts[URL] = URLCounts[URL] + 1\n",
    "                        else:\n",
    "                            URLCounts[URL] = 1\n",
    "\n",
    "results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result + \": \" + str(URLCounts[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben wir ein neues Problem: Wir sehen, dass viele Dateien angefragt werden, Dateien die überhaupt keine Webseiten sind, sondern nur von .html - Dateien eingebunden werden. Diese müssen wir natürlich ignorieren, wir interessieren uns dafür ja nicht.\n",
    "\n",
    "Daher entfernen wir im nächsten Schritt alle Adresse, die nicht auf den Schrägstrich \"/\" enden. Das liegt daran, dass ich weiß, dass all meine Artikel eine URL haben, die auf einen Schrägstrich endet - daher darf ich das tun. Hier verwende ich also weiteres Wissen, welches ich über die Daten habe, um diesen Schritt zu begründen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/: 77\n",
      "/orlando-headlines/: 36\n",
      "/comics-2/: 12\n",
      "/world/: 12\n",
      "/about/: 4\n",
      "/weather/: 4\n",
      "/australia/: 4\n",
      "/national-headlines/: 3\n",
      "/science/: 2\n",
      "/feed/: 2\n",
      "/sample-page/feed/: 2\n",
      "/technology/: 2\n",
      "/entertainment/: 1\n",
      "/travel/feed/: 1\n",
      "/san-jose-headlines/: 1\n",
      "/business/: 1\n"
     ]
    }
   ],
   "source": [
    "URLCounts = {}\n",
    "\n",
    "with open(logPath, \"r\") as f:\n",
    "    for line in (l.rstrip() for l in f):\n",
    "        match= format_pat.match(line)\n",
    "        if match:\n",
    "            access = match.groupdict()\n",
    "            agent = access['user_agent']\n",
    "            if (not('bot' in agent or 'spider' in agent or \n",
    "                    'Bot' in agent or 'Spider' in agent or\n",
    "                    'W3 Total Cache' in agent or agent =='-')):\n",
    "                request = access['request']\n",
    "                fields = request.split()\n",
    "                if (len(fields) == 3):\n",
    "                    (action, URL, protocol) = fields\n",
    "                    if (URL.endswith(\"/\")):\n",
    "                        if (action == 'GET'):\n",
    "                            if URL in URLCounts:\n",
    "                                URLCounts[URL] = URLCounts[URL] + 1\n",
    "                            else:\n",
    "                                URLCounts[URL] = 1\n",
    "\n",
    "results = sorted(URLCounts, key=lambda i: int(URLCounts[i]), reverse=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result + \": \" + str(URLCounts[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sieht jetzt schonmal etwas glaubwürdiger aus. Aber wenn man noch etwas weiter in die Daten hineinschaut sieht man, dass die Seiten mit \"/feed/\" etwas komisch aussehen, und dass immernoch ein paar Zugriffe von Suchmaschienen nicht herausgefiltert wurden. Dennoch - auf Basis dieser Daten sieht es so aus, dass Orlando News, World News und Comics die am häufigsten aufgerufenen Seiten sind. \n",
    "\n",
    "Das Fazit: Kenn dich mit den Daten aus. Hinterfrag immer was die Ergebnisse sind, und überprüfe die Ergebnisse, bevor du vorschnelle Schlüsse ziehst. Wenn deine Firma wegen einer leichtfertigen Entscheidung nachher richtig Geld verliert, kann das definitiv zu Problemen führen.\n",
    "\n",
    "Zudem: Bei jeden Schritt, überlege dir gut, ob du ihn durchführen darfst. Warum darfst du die Daten in jedem Schritt bereinigen? Bereinige die Daten nicht, weil dir das Ergebnis am Ende nicht passt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Ergebnisse sind noch nicht perfekt, die URL enthalten teilweise noch das Wort \"feed\", diese werden auch automatisiert abgerufen. Passe den Code so an, dass auch diese Einträge ignoriert werden. Wenn du Lust hast, schau dir das Log-File noch etwas genauer an - was für User-Agents rufen die /feed - Seiten auf? Wo könnten diese herkommen? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
